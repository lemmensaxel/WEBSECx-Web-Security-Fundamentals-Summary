\documentclass[../main.tex]{subfiles}
\begin{document}

\chapter{Securely handling untrusted data}

\section{Introduction}
\subsection{The problem with untrusted data}
\begin{itemize}
\item User-provided data is not the only kind of untrusted data. If you think this through, all dynamic data in a web application is untrusted in one way or another. Especially in the modern web, where many applications access the same underlying data stores.
\item In theory, handling untrusted data is not a hard problem. However in practice, things are a lot more complicated, and mistakes are easy to make.
\end{itemize}

\subsection{The root cause of injection attacks}
\begin{itemize}
\item \textbf{SQL injection} attacks are quite powerful: the provided input can change the structure of the SQL statement being executed. It can contain a query, and an instruction to delete the database.
\item The real problem is that the database server lacks context information. The database server does not know which part of the statement is data and which part is code.
\item Other injection vulnerabilities share the same root cause (e.g. \textbf{command injection}, \textbf{code injection}, \textbf{LDAP injection}, \textbf{XPath injection}).
\end{itemize}

\subsection{A decade of mitigating injection vulnerabilities}
\begin{itemize}
\item Recommend for developers to be involved. Make sure that the tools that they give you, the means that they give you to write secure code are actually the things that you want to use on a day to day basis. 
\end{itemize}

\section{Server-side injection attacks }
\subsection{Command injection vulnerabilities}
\begin{itemize}
\item In essence, a potential \textbf{command injection} vulnerability exists every time untrusted data ends up in an external command. A common source of untrusted data is user input. However, alternative sources, such as cookies or HTTP headers are also potential attack vectors.
\item Whenever a command is constructed using untrusted data, you need to implement additional defences against command injection attacks.
\end{itemize}

\subsection{Preventing command injection}
\begin{itemize}
\item Injection vulnerabilities follow from a lack of context at execution time
\item A first line of defence is strict \textbf{input validation}. It is easy to make the checks too restrictive, which breaks the application. But if the check is too permissive, the vulnerability remains.
\item Most programming languages offer functions to \textbf{escape dangerous shell characters}. This way the dangerous characters are encoded, and the shell is no longer confused between data and code.
\item Some languages offer a safe API to make system calls. Such an API accepts the command and its arguments as separate parameters. Separating the command and the data ensures that there can be no confusion between data and code.
\item Java offers protection against command injection attacks out of the box. But improper use of the \texttt{exec} method in Java, and its counterpart in .NET, can still cause injection vulnerabilities.
\end{itemize}

\subsection{SQL injection}
\begin{itemize}
\item A \textbf{SQL injection attack} allows the attacker to modify the SQL code that is executed by the database server.
\item SQL injection is one of the most dangerous problems in web applications. Both the consequences and prevalence of SQL injection vulnerabilities contribute to this status.
\item Injection vulnerabilities rank first in the OWASP top 10.
\item A common way to attack a select query is by injecting a \textbf{UNION statement}. The UNION statement tells the database server to execute both queries and combine the data into one dataset. This type of attack is well-suited to steal data from the database.
\item Another versatile attack is the insertion of a \textbf{boolean clause}. For example, many queries filter the results in the WHERE clause. By appending a boolean clause that is always true, the attacker can disable filtering. Consequences are the leaking of information, but also bypassing authorization checks.
\item Another way to modify the structure of the query is by injecting the comment symbol. When the database server encounters a comment symbol, everything after that is ignored. If the attacker injects the comment symbol, he can eliminate the trailing part of a query. The consequences can be severe since additional constraints are often put at the end of a query.
\item Tools like \textbf{sqlmap} collect a variety of potential attacks. They even support scanning applications for potential SQL vulnerabilities. These results from sqlmap paint a more complete picture on the complexity of SQL injection attacks.
\end{itemize}

\subsection{Preventing SQL injection}
\begin{itemize}
\item SQL injection vulnerabilities have a similar cause as command injection vulnerabilities.
\item A solid first line of defense is \textbf{input validation}.
\item Remember that input validation alone is not enough.
\item Use \textbf{prepared statements with variable binding} $\rightarrow$ provide the proper context information.
\item Unfortunately, variable binding does not work in all parts of a SQL statement. The names of tables and columns need to be specified up front, and cannot be bound later. But there are safe ways to handle untrusted data in these locations.
\item One way is to use the untrusted input to select a value from a whitelisted set of values. The explicit selection of a value ensures that untrusted data never ends up in the statement.
\item Also the encoding of special characters renders the untrusted data harmless. Note that encoding untrusted data for use in a SQL statement is complicated to get right. Every database has a particular set of special characters. Therefore, encoding should only be used as a last resort.
\item Finally, keep in mind that untrusted data can come from anywhere. User input is only the most obvious candidate. Other examples are cookies or HTTP headers.
\end{itemize}

\section{Client-side injection attacks}
\subsection{Traditional XSS attacks}
\begin{itemize}
\item An \textbf{Cross-site Scripting (XSS) vulnerability} allows an attacker to get a foothold in the application's browsing context (e.g. popping up an alert dialogue, defacement of a page, theft of sensitive information, session hijacking...).
\item \textbf{Browser Exploitation Framework (BeEF)}:  Offers a command-and-control interface. Once the attacker has hooked a browser, he can execute all kinds of commands with the click of a button.
\item \textbf{Reflected cross-site scripting}: A payload is sent to the server as part of the request data. The server incorporates the payload into the HTML page of the response. When the browser processes the page, it sees the payload data and mistakes it for code. This mistake results in the execution of malicious code (=\textbf{script injection attack}).
\item \textbf{Stored cross-site scripting}: The attacker injects the payload into the application's database. Whenever a user visits a page that displays this data, the payload will be embedded in the page. When the user's browser renders this page, it also executes the attacker's code. Note that this attack does not involve a cross-site request, and is executed entirely within the targeted application.
\item Each of these attacks has a different approach, but the result is the same. Both enable the execution of the attacker's code in the victim's browser, inside the application's context. These attacks succeed because the browser lacks the context to distinguish between data and code.
\end{itemize}

\subsection{Common defenses against XSS attacks}
\begin{itemize}
\item An easy way to mitigate this vulnerability is to apply input validation. Unfortunately, it only works well in the simplest cases.
\item The \textbf{XSS Filter Evasion Cheat Sheet} lists a large number of XSS filter bypasses.
\item A better solution is \textbf{output encoding}: dangerous characters are encoded to their harmless counterparts. Many frameworks and languages offer functions that encode dangerous characters for an HTML context.
\item The set of dangerous characters is different for each context. Dangerous characters in an HTML element context differ from those in a CSS or JavaScript context. That is why the proper mitigation technique is known as \textbf{context-sensitive output encoding}. Dangerous characters are still encoded, but the difference is that the context now determines which characters are dangerous $\rightarrow$ best mitigation strategy against XSS vulnerabilities.
\item Libraries offer encoding functions for all kinds of contexts in an HTML page (e.g. \textbf{OWASP Java Encoder library}).
\item \emph{What if the user-provided input is rich-text data, for example from an HTML editor?}\\
Applying context-sensitive output encoding in this scenario breaks legitimate functionality. That is why the answer to this problem is \textbf{sanitization}: a sanitization library parses the input and analyses its contents.
It removes potentially dangerous parts but keeps the rest intact. Do not try to write your own sanitization library. Use a well-vetted library, such as the \textbf{OWASP Java HTML Sanitizer}.
\end{itemize}

\subsection{DOM-based XSS attacks}
\begin{itemize}
\item JavaScript running in the browser can also modify the contents of a page. This JavaScript code can also use untrusted data, and insert it into the page in an insecure way, so this JavaScript code will also need to provide the proper context information to the browser. Such client-side XSS attacks are known as \textbf{DOM-based XSS}.
\item A DOM-based cross-site scripting attack occurs when legitimate code modifies the DOM in an insecure way.
\item The same separation exists between \textbf{reflected DOM-based XSS attacks} and \textbf{stored DOM-based XSS attacks}.
\item Server-side defenses are useless against DOM-based XSS attacks. The best way to prevent DOM-based cross-site scripting vulnerabilities is to use the proper \textbf{DOM APIs}. These APIs offer safe functions to create and insert elements and a way to put data inside an element, without the risk of causing a confusion between data and code.
\item Of course, using the proper DOM APIs is not always possible. In those cases, you can fall back on traditional XSS defenses.
\item Untrusted data can be encoded for the right context before inserting it into the page. Various \textbf{client-side encoding libraries} support encoding of data for different contexts.
\item Alternatively, \textbf{client-side sanitization libraries} transform untrusted HTML code into safe code (e.g. \textbf{DOMPurify}).
\item A recent study of the Alexa top 5000 websites has shown that at least 9.6 percent are vulnerable to DOM-based cross-site scripting $\rightarrow$ they are prevalent and dangerous.
\end{itemize}

\section{Advanced client-side attacks and defenses}
\subsection{Alternative injection attack vectors}
\begin{itemize}
\item alternative injection attacks use various types of content. Two typical examples are the injection of HTML code and CSS code. A bit more exotic is the injection of SVG code or vulnerable Flash files.
\item \textbf{HTML injection attack}: the attacker-provided data contains a piece of HTML code, which will end up in the generated page.
\item The injection of plain HTML elements can also have severe consequences (e.g. exfiltration of data,injecting hidden input fields...).
\item Ensuring that the browser does not confuse HTML in data fields as code by applying context-sensitive output encoding.
\item An alternative defense strategy is the use of sanitization. However, the effectiveness of sanitization against HTML injection attacks depends on the sanitizer. Some of these payloads use harmless HTML elements. As a result, a sanitizer may not see them as malicious or dangerous.
\item \textbf{CSS injection attack}: injection of seemingly harmless CSS code as part of a style element. Even the injection of plain CSS code can cause a lot of harm (e.g. defacement, execution of JavaScript code, right from within the CSS context...).
\item The proper defence is context-sensitive output encoding. For sanitization, it again depends on the specific sanitizer.
\end{itemize}

\subsection{HTML5 Sandboxing}
\begin{itemize}
\item A first step to reduce the impact of injection attacks is to enforce context isolation. The Same-Origin Policy can be used to isolate the main application context from potential untrusted parts.
\item \textbf{Origin-based isolation} is effective, but also tricky to implement. It requires splitting of the application into different components so that they can be deployed in different origins.
\item The \textbf{HTML5 sandbox attribute} allows you to impose additional constraints on an iframe. In essence, a sandboxed iframe offers a restricted environment, which can be used to isolate untrusted content.
\item You can customize the sandbox to your specific needs. Most of the restrictions can be turned off by adding a specific directives to the value of the attribute.
\item The real power of the sandbox attribute is the capability to isolate content in a unique origin. This feature gives you the benefits of origin-based isolation, without the hassle of using different origins. When you load a page from your origin in a sandboxed iframe, the browser substitutes the actual origin with a random and unique value. In practice, this means that this content will be isolated from every other context in the browser, regardless of where it was loaded from.
\item Combining the \textbf{allow-sameorigin} and \textbf{allow-scripts} permission enables a bypass-attack on the sandbox.So use one or the other, but never both together.
\end{itemize}

\subsection{Content Security Policy}
\begin{itemize}
\item Origin-based isolation and sandboxing can be used to isolate specific blocks of content. But it is a challenge to deploy these techniques as an application-wide second line of defense.
\item \textbf{Content Security Policy (CSP)}: a complex security policy with various options. It defines the intended behaviour of a page and prevents actions that violate these intentions. 
\item CSP offers control over various kinds of content, such as scripts, styles, and images.
\item For each of these resources, you can specify where they can originate from. Whenever the page requests resources that are not listed in the CSP policy, the browser refuses to load them.
\item Script content is highly interactive, which is why the script-src directive is quite complicated. Similar in complexity is the style-src directive, which controls stylesheets. Stylesheets are also considered to be interactive and are subject to the same restrictions as script content. By default, CSP prevents inline styles from being executed.
\item The default directive is used when a more specific directive is absent. If we remove the \textbf{img-src} directive from our policy but retain the \textbf{default-src} directive  and the page tries to load a remote image, the browser will use the default-src directive, since there is no img-src directive.
\item Whenever the browser detects a violation of a CSP policy, it shows an error message in the developer console. But of course, when a violation happens in the user's browser, these messages are not very useful. That is why CSP offers a reporting feature. To enable the reporting feature, you need to add the \textbf{report-uri} directive to the policy.
\item CSP also supports a \textbf{report-only} mode. In report-only mode, violations do not result in the blocking of the resource.
\end{itemize}

\begin{itemize}
\item Unfortunately, many applications depend on inline style and script code. They break when CSP is deployed, because of this limitation. That is why CSP supports an \textbf{unsafe-inline} keyword. Adding that keyword to the script-src, style-src or default-src directive re-enables inline style or code.
\item Of course, when inline code or style is enabled, CSP will not be able to protect your application against injection attacks. That is why you should never use unsafe-inline for scripts.
\item Hashes and nonces replace the use of unsafe-inline. As a result, if a policy uses both unsafe-inline and hashes/nonces, the browser will only use one of them. A modern browser will use the hashes and nonces, and ignore unsafe-inline. An older browser does not know about hashes and nonces, so it will ignore them, and use unsafe-inline. In essence, this mechanism supports backwards compatilibity with older browsers, while offering better security features to newer browsers.
\item \textbf{Hashes} are calculated on the contents of a script block, and uniquely identify a piece of code. By whitelisting a code block with a specific hash, you can re-enable inline scripts. Below is an example of a CSP policy with a hash.
\item Note that the use of hashes in a CSP policy is secure because the hash is directly correlated to the contents of the script block. Even if the attacker can inject script code, he can only inject code that is already white listed.
\item Hashes are well-suited to whitelist static code blocks in a page. But if part of the code block is dynamically generated, hashes become almost impossible to use. That is why CSP level 2 also supports a second mechanism: nonces.
\item A \textbf{nonce} is a random and unique value. Both the script block (using the \texttt{nonce=""} attribute) and the policy contain the nonce. If they match, the browser allows the script block to execute. The essence of using nonces is that attacker-injected code does not contain the nonce. Hence, it will not be executed.
\item But for nonces to be secure, they need to be unpredictable. An attacker cannot learn the nonce or predict the next value. Therefore, every response from the server should contain a different nonce. To avoid predictability, nonces should be derived from a secure random number generator. If these two conditions are met, then the attacker will never succeed in injecting a script block with a valid nonce.
\item Building a CSP policy requires you to whitelist a lot of resources. Once you have external dependencies, your whitelist starts growing rapidly. As a result, it is common to start whitelisting entire hosts.
\item Unfortunately, research from Google has shown that host-based whitelists can result in bypass attacks.
\item The first solution is to whitelist up to the file level. If you only whitelist explicit script files on a CDN, thereâ€™s no way to include potentially dangerous scripts. There is, however, one caveat to this approach. In many scenarios, whitelisting explicit files is next to impossible to get right, and to maintain over time.
\item An alternative solution is to use the \textbf{strict-dynamic} in combination with hashes and nonces. strict-dynamic was introduced in 2016 and is part of the upcoming level 3 specification of CSP. The strict-dynamic keyword tells the browser that already-trusted scripts are allowed to load their own resources.
\end{itemize}
\end{document}



































